{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils\n",
    "import warnings\n",
    "from LFDatatest import LFDatatest\n",
    "from DeviceParameters import to_device\n",
    "from MainNet_pfe_test import MainNet\n",
    "from Functions import CropLF, MergeLF,ComptPSNR,rgb2ycbcr\n",
    "from skimage.measure import compare_ssim \n",
    "import numpy as np\n",
    "import scipy.io as scio \n",
    "import scipy.misc as scim\n",
    "import os\n",
    "import logging,argparse\n",
    "from datetime import datetime\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.ion()\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "log = logging.getLogger()\n",
    "fh = logging.FileHandler('Testing_original.log')\n",
    "log.addHandler(fh)\n",
    "\n",
    "# Testing settings\n",
    "parser = argparse.ArgumentParser(description=\"Light Field Denoising\")\n",
    "parser.add_argument(\"--stageNum\", type=int, default=6, help=\"The number of stages\")\n",
    "parser.add_argument(\"--sasLayerNum\", type=int, default=4, help=\"The number of stages\")\n",
    "parser.add_argument(\"--batchSize\", type=int, default=1, help=\"Batch size\")\n",
    "parser.add_argument(\"--patchSize\", type=int, default=32, help=\"The size of croped LF patch\")\n",
    "parser.add_argument(\"--overlap\", type=int, default=4, help=\"The size of croped LF patch\")\n",
    "parser.add_argument(\"--measurementNum\", type=int, default=4, help=\"The number of measurements\")\n",
    "parser.add_argument(\"--angResolution\", type=int, default=7, help=\"The angular resolution of original LF\")\n",
    "parser.add_argument(\"--channelNum\", type=int, default=1, help=\"The number of input channels\")\n",
    "parser.add_argument(\"--modelPath\", type=str, default='./model/***pfe model***', help=\"Path for loading trained model \")\n",
    "parser.add_argument(\"--dataPath\", type=str, default='path_to/test_LFCA_Kalantari_4-10.mat', help=\"Path for loading testing data \")\n",
    "parser.add_argument(\"--savePath\", type=str, default='./results/', help=\"Path for saving results \")\n",
    "\n",
    "\n",
    "opt = parser.parse_known_args()[0]\n",
    "logging.info(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_dataset = LFDatatest(opt)\n",
    "dataloader = DataLoader(lf_dataset, batch_size=opt.batchSize,shuffle=False)\n",
    "model=MainNet(opt)\n",
    "model.load_state_dict(torch.load(opt.modelPath))\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    num = 0\n",
    "    avg_psnr = 0\n",
    "    avg_ssim = 0\n",
    "    for _,sample in enumerate(dataloader):\n",
    "        num=num+1\n",
    "        LF=sample['LF'] #test lf [b,u,v,x,y,c]\n",
    "        lfName=sample['lfName']\n",
    "        b,u,v,x,y,c = LF.shape   \n",
    "\n",
    "        # Crop the input LF into patches \n",
    "        LFStack,coordinate=CropLF(LF.permute(0,1,2,5,3,4),opt.patchSize, opt.overlap) #[b,n,u,v,c,x,y]\n",
    "        n=LFStack.shape[1]       \n",
    "        estiLFStack=torch.zeros(b,n,u,v,c,opt.patchSize,opt.patchSize)#[b,n,u,v,c,x,y]\n",
    "\n",
    "        # reconstruction\n",
    "        for i in range(LFStack.shape[1]):\n",
    "            codedImPatch=torch.zeros(b,opt.measurementNum,c,opt.patchSize,opt.patchSize)#[b,measurementNum,c,x,y]\n",
    "            estiLFPatch=torch.zeros(b,u,v,c,opt.patchSize,opt.patchSize)#[b,u,v,c,x,y]\n",
    "            for j in range(c):\n",
    "                estiLFPatch[:,:,:,j:j+1,:,:]=model(LFStack[:,i,:,:,j:j+1,:,:].cuda())  #[b,measurementNum,c,x,y] [b,u,v,c,x,y].\n",
    "            estiLFStack[:,i,:,:,:,:,:]=estiLFPatch #[b,n,u,v,c,x,y]\n",
    "\n",
    "        # Merge the patches into LF\n",
    "        estiLF=MergeLF(estiLFStack,coordinate,opt.overlap,x,y) \n",
    "        b,u,v,c,xCrop,yCrop=estiLF.shape\n",
    "        LF=LF[:,:,:, opt.overlap//2:opt.overlap//2+xCrop,opt.overlap//2:opt.overlap//2+yCrop,:]\n",
    "        lf_psnr = 0\n",
    "        lf_ssim = 0\n",
    "\n",
    "        #evaluation\n",
    "        for ind_uv in range(u*v):\n",
    "                lf_psnr += ComptPSNR(rgb2ycbcr(estiLF.permute(0,1,2,4,5,3).reshape(b,u*v,xCrop,yCrop,c)[0,ind_uv].cpu().numpy())[:,:,0],\n",
    "                                     rgb2ycbcr(LF.reshape(b,u*v,xCrop,yCrop,c)[0,ind_uv].cpu().numpy())[:,:,0])  / (u*v)\n",
    "\n",
    "                lf_ssim += compare_ssim(rgb2ycbcr(estiLF.permute(0,1,2,4,5,3).reshape(b,u*v,xCrop,yCrop,c)[0,ind_uv].cpu().numpy()*255.0)[:,:,0].astype(np.uint8),\n",
    "                                        rgb2ycbcr(LF.reshape(b,u*v,xCrop,yCrop,c)[0,ind_uv].cpu().numpy()*255.0)[:,:,0].astype(np.uint8),gaussian_weights=True,sigma=1.5,use_sample_covariance=False,multichannel=False) / (u*v)\n",
    "\n",
    "        avg_psnr += lf_psnr / len(dataloader)           \n",
    "        avg_ssim += lf_ssim / len(dataloader)\n",
    "        log.info('Index: %d  Scene: %s  PSNR: %.2f  SSIM: %.3f'%(num,lfName[0],lf_psnr,lf_ssim))\n",
    "        #save reconstructed LF\n",
    "        scio.savemat(os.path.join(opt.savePath,lfName[0]+'.mat'),\n",
    "                     {'lf_recons':torch.squeeze(estiLF).numpy()})\n",
    "\n",
    "\n",
    "    # #save coded mask\n",
    "    if opt.measurementNum==1:\n",
    "        plt.imsave(os.path.join(opt.savePath, 'mask.png'),\n",
    "                         torch.squeeze(255.0*model._modules['proj_init'].weight.data.reshape(-1,opt.angResolution,opt.angResolution).permute(1,2,0)).cpu().numpy())\n",
    "    if opt.measurementNum==2:\n",
    "        plt.imsave(os.path.join(opt.savePath, 'mask.png'),\n",
    "                         torch.squeeze(255.0*model._modules['proj_init'].weight.data.reshape(-1,opt.angResolution,opt.angResolution-1).permute(1,2,0)).cpu().numpy())\n",
    "    if opt.measurementNum==4:\n",
    "        plt.imsave(os.path.join(opt.savePath, 'mask.png'),\n",
    "                         torch.squeeze(255.0*model._modules['proj_init'].weight.data.reshape(-1,opt.angResolution,opt.angResolution).permute(1,2,0)).cpu().numpy())\n",
    "\n",
    "    log.info('Average PSNR: %.2f  SSIM: %.3f '%(avg_psnr,avg_ssim))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
